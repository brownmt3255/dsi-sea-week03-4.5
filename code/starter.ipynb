{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "___Hello? Can anyone hear me?___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<img src=\"https://media.giphy.com/media/xaMg6NGwH2fFS/giphy.gif\" alt=\"Title\" style=\"border: 5px solid #000000; padding: 10px; width: 250px; height: 200px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## There. Is that better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<img src=\"http://bestanimations.com/Sci-Fi/Aliens/little-grey-extraterrestial-aliens-animated-gif-image-10.gif\" alt=\"Title\" style=\"border: 5px solid #000000; padding: 10px; width: 250px; height: 200px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Good... Hello fellow person. My name is Hugh Man. I am also a person like you! Here is a picture of me at a normal human party with my normal human friends!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<img src=\"http://www.promvenues.com/blogs/media/Crazy%20Prom%20Themes%20for%20Teenagers%20to%20Spice%20up%20Their%20Party_142.jpg\" alt=\"Title\" style=\"border: 5px solid #000000; padding: 10px; width: 250px; height: 200px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Look how much fun we are having drinking everyday human liquids!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Anyways, I have sent this communication to ask you a few questions about normal human activities, that I also do. My human mother is very sick and doesn't get out from her two story Dutch Colonial condo as often as she would like. Here is a picture of her from yesterday."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<img src=\"http://previews.123rf.com/images/szefei/szefei1302/szefei130200062/18061194-Happy-mother-s-day-concept-Asian-senior-mother-showing-a-gift-and-carnation-flowers-at-home--Stock-Photo.jpg\" alt=\"Title\" style=\"border: 5px solid #000000; padding: 10px; width: 250px; height: 200px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## She was wondering about the state of technological / military advancement on your human planet. She is very fearful of planets with enough technology to shoot down class C starships from space. Can you help put her fears to rest? My assistant will beam the details to your computer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "___Beep___\n",
    "### Assistant here! I have updated your notebook with the proper protocols. Please follow the instructions provided.\n",
    "\n",
    "#### Requirements\n",
    "\n",
    "* Access the 'conspiracy' site (https://www.reddit.com/r/conspiracy.json). You should get the first 25 entries from the subreddit right away.\n",
    "* Make sure to keep track of the entry position, title, and upvotes for each entry in the subreddit\n",
    "* Crawl through each url. Extract all the text from each paragraph (they have a <**p**> tag). If there is no url, skip this step.\n",
    "* Crawl through each url. Extract all the links from each link tag (they have an <**a**> tag). If there is no url, skip this step.\n",
    "\n",
    "*** Bonus ***\n",
    "\n",
    "* Crawl through each of the comments. Extract all the text from the body keys of each comment\n",
    "\n",
    "#### Tips\n",
    "\n",
    "* Each entry on the site contains a key called \"permalink\" add it to your base url to navigate to that link's comments\n",
    "* Each entry on the site contains a key called \"url\". Use this link to navigate to the page described in the post\n",
    "\n",
    "<br>\n",
    "** Base Url => https://www.reddit.com **\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import urllib2\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "base = 'https://www.reddit.com'\n",
    "soup = BeautifulSoup(urllib2.urlopen('https://www.reddit.com/r/conspiracy.json').read())\n",
    "parsed_json = json.loads(soup.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>approved_by</th>\n",
       "      <th>archived</th>\n",
       "      <th>author</th>\n",
       "      <th>author_flair_css_class</th>\n",
       "      <th>author_flair_text</th>\n",
       "      <th>banned_by</th>\n",
       "      <th>clicked</th>\n",
       "      <th>contest_mode</th>\n",
       "      <th>created</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>...</th>\n",
       "      <th>stickied</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>subreddit_id</th>\n",
       "      <th>suggested_sort</th>\n",
       "      <th>thumbnail</th>\n",
       "      <th>title</th>\n",
       "      <th>ups</th>\n",
       "      <th>url</th>\n",
       "      <th>user_reports</th>\n",
       "      <th>visited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>axolotl_peyotl</td>\n",
       "      <td>AXO</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.478140e+09</td>\n",
       "      <td>1.478111e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>conspiracy</td>\n",
       "      <td>t5_2qh4r</td>\n",
       "      <td>None</td>\n",
       "      <td>self</td>\n",
       "      <td>Clinton Coup vs. Counter-Coup</td>\n",
       "      <td>1162</td>\n",
       "      <td>https://www.reddit.com/r/conspiracy/comments/5...</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>asherlina</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.478357e+09</td>\n",
       "      <td>1.478328e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>conspiracy</td>\n",
       "      <td>t5_2qh4r</td>\n",
       "      <td>None</td>\n",
       "      <td>http://b.thumbs.redditmedia.com/Sx4vaVqa9kTHk-...</td>\n",
       "      <td>New Assange Interview</td>\n",
       "      <td>383</td>\n",
       "      <td>https://www.rt.com/news/365405-assange-pilger-...</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>White_Noise_Scream</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.478379e+09</td>\n",
       "      <td>1.478351e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>conspiracy</td>\n",
       "      <td>t5_2qh4r</td>\n",
       "      <td>None</td>\n",
       "      <td>http://b.thumbs.redditmedia.com/ufTOlbOCfJR0ai...</td>\n",
       "      <td>It Just Got Way Bigger: Wikileaks Bombshell Re...</td>\n",
       "      <td>2859</td>\n",
       "      <td>http://www.silverdoctors.com/headlines/world-n...</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>Bernie4Ever</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.478380e+09</td>\n",
       "      <td>1.478351e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>conspiracy</td>\n",
       "      <td>t5_2qh4r</td>\n",
       "      <td>None</td>\n",
       "      <td>http://b.thumbs.redditmedia.com/d8hUWjIONjKHE2...</td>\n",
       "      <td>Poll: 83 Percent Say Hillary Clinton Guilty of...</td>\n",
       "      <td>1504</td>\n",
       "      <td>http://www.breitbart.com/2016-presidential-rac...</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>TFC4104</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.478410e+09</td>\n",
       "      <td>1.478382e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>conspiracy</td>\n",
       "      <td>t5_2qh4r</td>\n",
       "      <td>None</td>\n",
       "      <td>self</td>\n",
       "      <td>FBI saves 81 children in child sex ring. Conne...</td>\n",
       "      <td>324</td>\n",
       "      <td>https://www.reddit.com/r/conspiracy/comments/5...</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  approved_by archived              author author_flair_css_class  \\\n",
       "0        None    False      axolotl_peyotl                    AXO   \n",
       "1        None    False           asherlina                   None   \n",
       "2        None    False  White_Noise_Scream                   None   \n",
       "3        None    False         Bernie4Ever                   None   \n",
       "4        None    False             TFC4104                   None   \n",
       "\n",
       "  author_flair_text banned_by clicked contest_mode       created  \\\n",
       "0              None      None   False        False  1.478140e+09   \n",
       "1              None      None   False        False  1.478357e+09   \n",
       "2              None      None   False        False  1.478379e+09   \n",
       "3              None      None   False        False  1.478380e+09   \n",
       "4              None      None   False        False  1.478410e+09   \n",
       "\n",
       "    created_utc   ...   stickied   subreddit  subreddit_id suggested_sort  \\\n",
       "0  1.478111e+09   ...       True  conspiracy      t5_2qh4r           None   \n",
       "1  1.478328e+09   ...       True  conspiracy      t5_2qh4r           None   \n",
       "2  1.478351e+09   ...      False  conspiracy      t5_2qh4r           None   \n",
       "3  1.478351e+09   ...      False  conspiracy      t5_2qh4r           None   \n",
       "4  1.478382e+09   ...      False  conspiracy      t5_2qh4r           None   \n",
       "\n",
       "                                           thumbnail  \\\n",
       "0                                               self   \n",
       "1  http://b.thumbs.redditmedia.com/Sx4vaVqa9kTHk-...   \n",
       "2  http://b.thumbs.redditmedia.com/ufTOlbOCfJR0ai...   \n",
       "3  http://b.thumbs.redditmedia.com/d8hUWjIONjKHE2...   \n",
       "4                                               self   \n",
       "\n",
       "                                               title   ups  \\\n",
       "0                      Clinton Coup vs. Counter-Coup  1162   \n",
       "1                              New Assange Interview   383   \n",
       "2  It Just Got Way Bigger: Wikileaks Bombshell Re...  2859   \n",
       "3  Poll: 83 Percent Say Hillary Clinton Guilty of...  1504   \n",
       "4  FBI saves 81 children in child sex ring. Conne...   324   \n",
       "\n",
       "                                                 url user_reports visited  \n",
       "0  https://www.reddit.com/r/conspiracy/comments/5...           []   False  \n",
       "1  https://www.rt.com/news/365405-assange-pilger-...           []   False  \n",
       "2  http://www.silverdoctors.com/headlines/world-n...           []   False  \n",
       "3  http://www.breitbart.com/2016-presidential-rac...           []   False  \n",
       "4  https://www.reddit.com/r/conspiracy/comments/5...           []   False  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Access the 'conspiracy' site (https://www.reddit.com/r/conspiracy.json).\n",
    "#You should get the first 25 entries from the subreddit right away.\n",
    "\n",
    "raw = []\n",
    "\n",
    "for a in parsed_json['data']['children']:\n",
    "        raw.append(a['data'])\n",
    "\n",
    "df = pd.DataFrame(raw)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Error 403: Forbidden\n",
      "HTTP Error 429: Too Many Requests\n",
      "HTTP Error 429: Too Many Requests\n",
      "HTTP Error 429: Too Many Requests\n",
      "HTTP Error 429: Too Many Requests\n",
      "HTTP Error 429: Too Many Requests\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "#Crawl through each url. \n",
    "#Extract all the text from each paragraph (they have a <**p**> tag). If there is no url, skip this step.\n",
    "paragraph_dicty = {}\n",
    "url_dicty = {}\n",
    "count = 0\n",
    "\n",
    "# for each url\n",
    "for url in df['url']:\n",
    "    try:\n",
    "        soup = BeautifulSoup(urllib2.urlopen(url).read(), \"lxml\")\n",
    "        \n",
    "        plist = []\n",
    "        list2 = []\n",
    "        \n",
    "        #Paragraph\n",
    "        for idx, p in enumerate(soup.find_all('p')):\n",
    "            #print \"<=== p ===>\", idx\n",
    "            plist.append(p.text.strip())\n",
    "            \n",
    "        paragraph_dicty[count] = plist\n",
    "        \n",
    "        #URL\n",
    "        for idx, u in enumerate(soup.find_all('a',href=True)):\n",
    "            #print \"<=== u ===>\", idx\n",
    "            list2.append(u['href'])\n",
    "            \n",
    "        url_dicty[count] = list2\n",
    "\n",
    "    except Exception as e:\n",
    "        print e\n",
    "        paragraph_dicty[count] = []\n",
    "        url_dicty[count] = []\n",
    "        \n",
    "    count += 1\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'use the following search parameters to narrow your results:'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraph_dicty.values()[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Cleaning..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Look through each of your words from your paragraph collecting. Remove as many of the nonsense values as you can."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "rejects = ['the','and','to','a','this','is','on','has','new','in', \n",
    "           'it', 'have', 'was','but','i','about','be','not','if','at',\n",
    "           'an','of','that','by','from','as','with','for','are','were','or', 'he','they','you','what','there','we','so',\n",
    "           'been','your','loading', 'working','nLoading','loading playlists','the','playlists','n','','n'','u'',' ',\n",
    "           word,'i','all','the','ago0']\n",
    "\n",
    "rejects += [str(x) for x in range(10)]\n",
    "\n",
    "# Function to remove special characters\n",
    "def replaceText(stringy):\n",
    "    if stringy.__class__.__name__ in  ['str', 'unicode']:\n",
    "        new_stringy = re.sub(\"[^0-9a-zA-Z']\", \"\",stringy)\n",
    "        if not new_stringy:\n",
    "            return ''\n",
    "        return str(new_stringy)\n",
    "    return stringy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['use',\n",
       " 'following',\n",
       " 'parameters',\n",
       " 'narrow',\n",
       " 'results',\n",
       " 'eg',\n",
       " 'subredditaww',\n",
       " 'siteimgurcom',\n",
       " 'dog',\n",
       " 'see']"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listy = []\n",
    "\n",
    "for a in paragraph_dicty.values():\n",
    "    for x in a:\n",
    "        listy.append(x.split(' '))\n",
    "\n",
    "listy2 = [item for sublist in listy for item in sublist]\n",
    "\n",
    "listy3 = [replaceText(x.lower()) for x in listy2 if x not in rejects]\n",
    "\n",
    "listy3[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Now look at the links that you collected. Everything that doesn't begin with an http:// or an https:// is a direct link 99.9% of the time. Remove all links that don't begin with http:// or https://."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.reddit.com/r/announcements/', 'https://www.reddit.com/r/Art/', 'https://www.reddit.com/r/AskReddit/']\n"
     ]
    }
   ],
   "source": [
    "url_listy = list(url_dicty.items())[0][1]\n",
    "\n",
    "\n",
    "listy4 = []\n",
    "for x in url_listy:\n",
    "    if 'http://' in x.encode('ascii','ignore') or 'https://' in x.encode('ascii','ignore'):\n",
    "        listy4.append(x)\n",
    "\n",
    "print listy4[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Munging (aka digging into the data)..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Every thing looks good buddy. Let's total up and print the top 10 words found in each of the urls with the subreddit's title above. Be sure to note any reference to class C starships in your report. O, and don't forget to remove the unnecessary words from the total. I don't think Supreme Commander Hugh Man would like to see words like 'the' and 'and' in his report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "points      237\n",
       "i           216\n",
       "            206\n",
       "children    204\n",
       "days        185\n",
       "clinton     133\n",
       "the         129\n",
       "ago0        104\n",
       "us           86\n",
       "hillary      83\n",
       "dtype: int64"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URL_Words_Series = pd.Series(listy3)\n",
    "\n",
    "word = URL_Words_Series[2]\n",
    "\n",
    "URL_Words_Series.value_counts()[0:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Those totals seem pretty small to me. I don't think Mr. Man's mother would approve of those results. Let's compile the words from the 10 entries with the highest upvotes. No need to print out the titles again. Just the top 10 words should be sufficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "points      237\n",
       "i           216\n",
       "            206\n",
       "children    204\n",
       "days        185\n",
       "clinton     133\n",
       "the         129\n",
       "ago0        104\n",
       "us           86\n",
       "hillary      83\n",
       "dtype: int64"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URL_Words_Series.value_counts()[0:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Let's see how far this site's human tentacles spread! Print out a count of the top 10 base urls from your combined scrubbed links. \n",
    "\n",
    "___Remember a base url is everything after the first 'http://' or 'https://' and before the first '/' in a url. For example: the base url for https://www.google.com/intl/en/policies/privacy/ is www.google.com___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "www.reddit.com                558\n",
      "www.youtube.com                 8\n",
      "en.wikipedia.org                7\n",
      "www.oxforddictionaries.com      3\n",
      "np.reddit.com                   2\n",
      "redd.it                         2\n",
      "twitter.com                     2\n",
      "youtu.be                        2\n",
      "www.nydailynews.com             1\n",
      "www.reuters.com                 1\n",
      "exopolitics.blogs.com           1\n",
      "www.whale.to                    1\n",
      "imgur.com                       1\n",
      "reddit.zendesk.com              1\n",
      "stevepieczenik.com              1\n",
      "topdocumentaryfilms.com         1\n",
      "about.reddit.com                1\n",
      "pbs.twimg.com                   1\n",
      "www.imdb.com                    1\n",
      "itunes.apple.com                1\n",
      "www.dailykos.com                1\n",
      "m.reddit.com                    1\n",
      "r.go1dfish.me                   1\n",
      "www.santafe.edu                 1\n",
      "www.ted.com                     1\n",
      "play.google.com                 1\n",
      "redditgifts.com                 1\n",
      "i.imgur.com                     1\n",
      "redefininggod.com               1\n",
      "www.infowars.com                1\n",
      "kiwiirc.com                     1\n",
      "www.nytimes.com                 1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "listy = []\n",
    "\n",
    "for x in listy4:\n",
    "    listy.append(x.split('/')[2])\n",
    "\n",
    "print pd.Series(listy).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# These are serious bonus questions. \n",
    "<br>\n",
    "** Not for the faint of heart! **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Assistant back! Good work human friend. Let's total up and print the top 10 words found in all comment sections. In addition to starships, make sure there is no mention of aliens or lizard people. We don't want to scare Mr. Man's mother with ideas that obviously aren't true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Oops! Looks like we made a mistake. The word each and both is inconveniently close in Zar... I mean English. Please find the top 10 combined word totals from the comments and urls for ___EACH___ entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Good work friend! We can now send this data back to the human lab for analysis. Until next time guy. This is Hugh Man out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<img src=\"https://media.tenor.co/images/c44fc07f543327c1073653ce8e99c17e/raw\" alt=\"Title\" style=\"border: 5px solid #000000; padding: 10px; width: 250px; height: 200px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<img src=\"https://media.giphy.com/media/xaMg6NGwH2fFS/giphy.gif\" alt=\"Title\" style=\"border: 5px solid #000000; padding: 10px; width: 250px; height: 200px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = range(5)\n",
    "b = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def checkError(x):\n",
    "    try:\n",
    "        return int(x)\n",
    "    except Exception as e:\n",
    "        print e\n",
    "        return -1\n",
    "b = a\n",
    "print b\n",
    "del b[0]\n",
    "\n",
    "print checkError('5')\n",
    "print checkError('4k')\n",
    "print checkError('cool')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
